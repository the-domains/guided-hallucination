<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title><![CDATA[guided hallucination]]></title>
        <description><![CDATA[guided hallucination]]></description>
        <link>https://thegrid.ai/guided-hallucination/</link>
        <generator>The Grid</generator>
        <lastBuildDate>Wed, 24 Feb 2016 15:55:49 GMT</lastBuildDate>
        <atom:link href="https://thegrid.ai/guided-hallucination/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Exploring the Intersection of Art and Machine Intelligence]]></title>
            <description><![CDATA[<article><h1>Exploring the Intersection of Art and Machine Intelligence</h1><p>In June of last year, we published a story about a visualization techniques that helped to understand how neural networks carried out difficult visual classification tasks. In addition to helping us gain a deeper understanding of how NNs worked, these techniques also produced strange, wonderful and oddly compelling images.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/1032e404bf324fc9bc14b4baa214f5b6e275e23e.jpg"></article>]]></description>
            <link>http://googleresearch.blogspot.com/2016/02/exploring-intersection-of-art-and.html</link>
            <guid isPermaLink="false">aece79f2-04ce-42ae-9638-c8a113cdc69c</guid>
            <pubDate>Wed, 24 Feb 2016 15:54:34 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Class visualization with bilateral filte...]]></title>
            <description><![CDATA[<article><h1>Class visualization with bilateral filte...</h1><p>Class visualization with bilateral filtersHigh resolution neural network outputs from DeepDream by Mike Tyka illustrate clearer visuals of machine understanding of subjects:A while ago I played with style visualizations and bilateral filters. The latter have the nice property of filtering out noise but preserving edges. Here are some example class from GoogLeNet (Inception network).</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/ea4bd1df2df4d4422e4b4fe83642b7fd960a83a8.jpg"></article>]]></description>
            <link>http://prostheticknowledge.tumblr.com/post/138876466996/class-visualization-with-bilateral-filters-high</link>
            <guid isPermaLink="false">bdf71528-8455-4580-b36d-102b37085234</guid>
            <pubDate>Thu, 11 Feb 2016 01:05:12 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Visual Turing Test]]></title>
            <description><![CDATA[<article><h1>Visual Turing Test</h1><p>Figure out if paintings are made by a human or by a computer.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/6664a0b57d2a5f067e60c6b03d2afe9e703592a8.jpg"></article>]]></description>
            <link>http://turing.deepart.io/</link>
            <guid isPermaLink="false">360d0c3b-00ee-414f-9f20-9cb4ef4c1e9f</guid>
            <pubDate>Tue, 09 Feb 2016 00:49:39 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[No title]]></title>
            <description><![CDATA[<img alt="This is the paper I started from&colon; http&colon;&sol;&sol;arxiv&period;org&sol;abs&sol;1601&period;04589 I refer to the whole class of algorithm as &num;NeuralPatches&period;" src="https://pbs.twimg.com/media/CaLDrCZWkAAgD0v.png:large">]]></description>
            <link>https://twitter.com/alexjc/status/694332438118567936</link>
            <guid isPermaLink="false">f7784d87-4b83-45be-8f40-870e91896d80</guid>
            <pubDate>Sat, 06 Feb 2016 15:18:39 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Listen to Darwintunes: random music evolving its way to beauty]]></title>
            <description><![CDATA[<article><h1>Listen to Darwintunes: random music evolving its way to beauty</h1><p>Darwintunes are short musical loops that mutate and evolve as listeners vote: "the higher rated loops get to have sex and have baby loops which form the next generation, to be rated, have sex, have babies and so on." The examples given start out as warbly bursts of random noise.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/05f42c4b87ef9037d3b24d01a4c149751d2eb30b.jpg"></article>]]></description>
            <link>http://boingboing.net/2016/01/22/listen-to-darwintunes-random.html</link>
            <guid isPermaLink="false">19e18eb4-8fb5-42a6-b899-1cbbd7b97aa2</guid>
            <pubDate>Fri, 22 Jan 2016 17:37:14 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Picasso painting on glass through his Blue, African, and Cubist periods]]></title>
            <description><![CDATA[<article><h1>Picasso painting on glass through his Blue, African, and Cubist periods</h1><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/7d3c5947d4fea35d1f753fe6b3629081f937aec9.jpg"></article>]]></description>
            <link>https://www.flickr.com/photos/genekogan/21772440906/in/dateposted-public/lightbox/</link>
            <guid isPermaLink="false">ac7c0033-88be-462a-9e94-0974d4b08647</guid>
            <pubDate>Thu, 21 Jan 2016 17:15:19 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[tree_hokusai2]]></title>
            <description><![CDATA[<article><h1>tree_hokusai2</h1><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/11edc9e9f331a6bd8646ad3945e2f8dcfd88b9d1.jpg"></article>]]></description>
            <link>https://www.flickr.com/photos/genekogan/23836655913/in/dateposted-public/lightbox/</link>
            <guid isPermaLink="false">c2f01d32-f663-4b3f-9ec3-57eb36804985</guid>
            <pubDate>Tue, 19 Jan 2016 01:57:04 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Experiments with style transfer [Continu...]]></title>
            <description><![CDATA[<article><h1>Experiments with style transfer [Continu...</h1><p>Experiments with style transfer [Continued]Coder and artist Mike Tyka experiments further with the Stylenet method of translating visual style from one image to the next, including applying an infinite zoom effect and visualizing certain parts of the neural net interpretation:Style transfer zoom movie.Hey this worked really well for DeepDream - why not try it for style transfer?Images from top-level activations onlyThe paper covers this but I thought it would be fun to try regenerating an image by using only the highest layer content activations with no style.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/b15bc54dcdf7559442d880d605ece64556d6a54d.gif"></article>]]></description>
            <link>http://prostheticknowledge.tumblr.com/post/137043316091/experiments-with-style-transfer-continued-coder</link>
            <guid isPermaLink="false">5d923aad-bb2a-450d-a1de-bbd9f9d372c3</guid>
            <pubDate>Thu, 14 Jan 2016 20:49:30 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow]]></title>
            <description><![CDATA[<article><h1>Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow</h1><p>Fake Kanji characters generated from a LSTM-Mixture Density Network in SVG Format using sketch-rnn. Code available on github. Note: Kanji (漢字) is the Japanese pronunciation for Chinese Characters, and I use these two terms interchangeably depending on the context. This is the third post in a series of blog posts logging my experiments with with TensorFlow.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/378f8c80f7215de13969bf9cc7e17e41487b8176.jpg"></article>]]></description>
            <link>http://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/</link>
            <guid isPermaLink="false">3397ab6c-299e-46b8-bbd3-7b8ed2b13631</guid>
            <pubDate>Mon, 28 Dec 2015 20:03:17 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[The four painters: A Video Work Created with Deep Learning]]></title>
            <description><![CDATA[<article><h1>The four painters: A Video Work Created with Deep Learning</h1><p>the four painters from takuya on Vimeo. Deep Learning is newly emerged Machine Learning technology and it has high quality in image recognition. With this technology, the computer now can understand artist's painting style and can imitate it. This means people can see the 'scenes' where the painters were seeing because a work is a scene seen through the painter's eyes.</p><img src="https://s3-us-west-2.amazonaws.com/the-grid-img/p/443131e17254589f1cccc71d5ca92e3d7627426d.jpg"></article>]]></description>
            <link>http://odoruinu.net/blog/2015/12/23/the-four-painters-a-video-work-created-with-deep-learning/</link>
            <guid isPermaLink="false">1e9eb611-77b5-44b7-a453-b7ec9e8f8323</guid>
            <pubDate>Sun, 27 Dec 2015 15:01:12 GMT</pubDate>
        </item>
    </channel>
</rss>